{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhHb3XgZXuGJWDbHwu863v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT21158186/INTERVIEW-PROCESSING-SYSTEM/blob/IT21158186-Deneth_Pinsara-Model_Train/Image_Classify_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow\n",
        "!pip install kaggle\n",
        "\n",
        "# Kaggle API token setup (Make sure your Kaggle JSON file is uploaded to Colab)\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "\n",
        "# Download datasets using Kaggle API\n",
        "!kaggle datasets download -d ziadhanyai/fashion-six-classes\n",
        "!kaggle datasets download -d itsahmad/indoor-scenes-cvpr-2019\n",
        "\n",
        "# Extract datasets\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/fashion-six-classes.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/fashion')\n",
        "with zipfile.ZipFile('/content/indoor-scenes-cvpr-2019.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/indoor')\n",
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Step 1: Prepare the datasets\n",
        "# Define directories\n",
        "fashion_dir = '/content/fashion/Fashion'\n",
        "indoor_dir = '/content/indoor/indoorCVPR_09/Images'\n",
        "\n",
        "# Create a structured directory for Dress Classification (Formal vs Casual)\n",
        "os.makedirs('/content/dress_data/formal', exist_ok=True)\n",
        "os.makedirs('/content/dress_data/casual', exist_ok=True)\n",
        "\n",
        "for category in ['Formal']:\n",
        "    src = os.path.join(fashion_dir, category)\n",
        "    dest = '/content/dress_data/formal'\n",
        "    for img in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, img), os.path.join(dest, img))\n",
        "\n",
        "for category in ['T-Shirt', 'Hoodie', 'Accessories']:\n",
        "    src = os.path.join(fashion_dir, category)\n",
        "    dest = '/content/dress_data/casual'\n",
        "    for img in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, img), os.path.join(dest, img))\n",
        "\n",
        "# Create a structured directory for Background Classification (Clean vs Messy)\n",
        "os.makedirs('/content/background_data/clean', exist_ok=True)\n",
        "os.makedirs('/content/background_data/messy', exist_ok=True)\n",
        "\n",
        "clean_folders = ['classroom', 'computerroom', 'office']\n",
        "messy_folders = [folder for folder in os.listdir(indoor_dir) if folder not in clean_folders]\n",
        "\n",
        "for folder in clean_folders:\n",
        "    src = os.path.join(indoor_dir, folder)\n",
        "    dest = '/content/background_data/clean'\n",
        "    for img in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, img), os.path.join(dest, img))\n",
        "\n",
        "for folder in messy_folders:\n",
        "    src = os.path.join(indoor_dir, folder)\n",
        "    dest = '/content/background_data/messy'\n",
        "    for img in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, img), os.path.join(dest, img))\n",
        "\n",
        "# Step 2: Data Generators for Dress and Background Models\n",
        "dress_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "background_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "dress_train = dress_datagen.flow_from_directory(\n",
        "    '/content/dress_data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "dress_val = dress_datagen.flow_from_directory(\n",
        "    '/content/dress_data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "background_train = background_datagen.flow_from_directory(\n",
        "    '/content/background_data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "background_val = background_datagen.flow_from_directory(\n",
        "    '/content/background_data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Step 3: Model Creation Function\n",
        "def create_model():\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 4: Train the Dress Classification Model\n",
        "print(\"Training Dress Classification Model...\")\n",
        "dress_model = create_model()\n",
        "dress_history = dress_model.fit(\n",
        "    dress_train,\n",
        "    steps_per_epoch=dress_train.samples // dress_train.batch_size,\n",
        "    validation_data=dress_val,\n",
        "    validation_steps=dress_val.samples // dress_val.batch_size,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Step 5: Train the Background Classification Model\n",
        "print(\"Training Background Classification Model...\")\n",
        "background_model = create_model()\n",
        "background_history = background_model.fit(\n",
        "    background_train,\n",
        "    steps_per_epoch=background_train.samples // background_train.batch_size,\n",
        "    validation_data=background_val,\n",
        "    validation_steps=background_val.samples // background_val.batch_size,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Both models are now trained\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXSkWxQeexql",
        "outputId": "0765011a-215c-4a16-e62a-4304429b3855"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/ziadhanyai/fashion-six-classes\n",
            "License(s): apache-2.0\n",
            "fashion-six-classes.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/itsahmad/indoor-scenes-cvpr-2019\n",
            "License(s): DbCL-1.0\n",
            "indoor-scenes-cvpr-2019.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Found 2449 images belonging to 2 classes.\n",
            "Found 612 images belonging to 2 classes.\n",
            "Found 12397 images belonging to 2 classes.\n",
            "Found 3098 images belonging to 2 classes.\n",
            "Training Dress Classification Model...\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 4s/step - accuracy: 0.6341 - loss: 0.6579 - val_accuracy: 0.6513 - val_loss: 0.6466\n",
            "Epoch 2/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6936 - val_accuracy: 1.0000 - val_loss: 0.4358\n",
            "Epoch 3/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 0.6571 - loss: 0.6469 - val_accuracy: 0.6513 - val_loss: 0.6471\n",
            "Epoch 4/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5625 - loss: 0.7115 - val_accuracy: 1.0000 - val_loss: 0.4509\n",
            "Epoch 5/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 4s/step - accuracy: 0.6489 - loss: 0.6509 - val_accuracy: 0.6530 - val_loss: 0.6457\n",
            "Epoch 6/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.6713 - val_accuracy: 0.7500 - val_loss: 0.5830\n",
            "Epoch 7/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 3s/step - accuracy: 0.6545 - loss: 0.6550 - val_accuracy: 0.6546 - val_loss: 0.6444\n",
            "Epoch 8/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.6519 - val_accuracy: 0.5000 - val_loss: 0.7420\n",
            "Epoch 9/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 4s/step - accuracy: 0.6550 - loss: 0.6474 - val_accuracy: 0.6546 - val_loss: 0.6452\n",
            "Epoch 10/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.6260 - val_accuracy: 0.5000 - val_loss: 0.7319\n",
            "Training Background Classification Model...\n",
            "Epoch 1/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1150s\u001b[0m 3s/step - accuracy: 0.9647 - loss: 0.1598 - val_accuracy: 0.9785 - val_loss: 0.1058\n",
            "Epoch 2/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.3185 - val_accuracy: 0.9615 - val_loss: 0.1775\n",
            "Epoch 3/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1143s\u001b[0m 3s/step - accuracy: 0.9757 - loss: 0.1217 - val_accuracy: 0.9785 - val_loss: 0.1068\n",
            "Epoch 4/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.9615 - val_loss: 0.1825\n",
            "Epoch 5/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1146s\u001b[0m 3s/step - accuracy: 0.9786 - loss: 0.1082 - val_accuracy: 0.9785 - val_loss: 0.1038\n",
            "Epoch 6/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.9615 - val_loss: 0.1686\n",
            "Epoch 7/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 3s/step - accuracy: 0.9772 - loss: 0.1152 - val_accuracy: 0.9782 - val_loss: 0.1129\n",
            "Epoch 8/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
            "Epoch 9/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 3s/step - accuracy: 0.9789 - loss: 0.1094 - val_accuracy: 0.9785 - val_loss: 0.1042\n",
            "Epoch 10/10\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9688 - loss: 0.1736 - val_accuracy: 0.9615 - val_loss: 0.1726\n",
            "Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Step 6: Evaluate Dress Classification Model\n",
        "print(\"Evaluating Dress Classification Model...\")\n",
        "dress_val.reset()  # Reset the generator for consistency\n",
        "y_true_dress = dress_val.classes  # Ground truth labels\n",
        "y_pred_dress = (dress_model.predict(dress_val) > 0.5).astype(\"int32\").flatten()  # Predictions\n",
        "\n",
        "# Calculate accuracy\n",
        "dress_accuracy = accuracy_score(y_true_dress, y_pred_dress)\n",
        "print(f\"Dress Classification Accuracy: {dress_accuracy:.2f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "dress_class_names = list(dress_val.class_indices.keys())\n",
        "print(\"Dress Classification Report:\")\n",
        "print(classification_report(y_true_dress, y_pred_dress, target_names=dress_class_names))\n",
        "\n",
        "# Step 7: Evaluate Background Classification Model\n",
        "print(\"Evaluating Background Classification Model...\")\n",
        "background_val.reset()  # Reset the generator for consistency\n",
        "y_true_background = background_val.classes  # Ground truth labels\n",
        "y_pred_background = (background_model.predict(background_val) > 0.5).astype(\"int32\").flatten()  # Predictions\n",
        "\n",
        "# Calculate accuracy\n",
        "background_accuracy = accuracy_score(y_true_background, y_pred_background)\n",
        "print(f\"Background Classification Accuracy: {background_accuracy:.2f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "background_class_names = list(background_val.class_indices.keys())\n",
        "print(\"Background Classification Report:\")\n",
        "print(classification_report(y_true_background, y_pred_background, target_names=background_class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEyjIbrsjZiX",
        "outputId": "41628510-1c8a-476e-ee87-b99f6d419bc0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Dress Classification Model...\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step\n",
            "Dress Classification Accuracy: 0.65\n",
            "Dress Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      casual       0.65      1.00      0.79       400\n",
            "      formal       0.00      0.00      0.00       212\n",
            "\n",
            "    accuracy                           0.65       612\n",
            "   macro avg       0.33      0.50      0.40       612\n",
            "weighted avg       0.43      0.65      0.52       612\n",
            "\n",
            "Evaluating Background Classification Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step\n",
            "Background Classification Accuracy: 0.98\n",
            "Background Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       clean       0.00      0.00      0.00        67\n",
            "       messy       0.98      1.00      0.99      3031\n",
            "\n",
            "    accuracy                           0.98      3098\n",
            "   macro avg       0.49      0.50      0.49      3098\n",
            "weighted avg       0.96      0.98      0.97      3098\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}